import tensorflow as tf
import numpy as np

#define NN
def add_layer(inputs, in_size, out_size, activation_func = None ):
	
	Weights = tf.Variable(tf.random_normal([in_size, out_size]))
	biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)
	Wx_plus_b = tf.matmul(inputs, Weights) + biases

	if activation_func is None:
		outputs = Wx_plus_b
	else:
		outputs = activation_func(Wx_plus_b)
	
	return outputs

#input data generated by scoreGenerator.py
fin = open('input.txt', 'r')
datas = fin.readlines()
x_data = []
y_data = []
for line in datas:
	line.strip('\n')
	temp =  line.split(" ")
	x_data.append([int(temp[0]), int(temp[1])])
	y_data.append([int(temp[2])])
del temp
x_data = np.array(x_data)
y_data = np.array(y_data)

x = tf.placeholder(tf.float32, [None, 2])
y = tf.placeholder(tf.float32, [None, 1])


#There are two layer
layer1 = add_layer(x, 2, 10, activation_func = tf.nn.relu)
prediction = add_layer(layer1, 10, 1, activation_func = None)

#loss for train
loss = tf.reduce_mean(tf.reduce_sum(tf.square(y - prediction),
									 reduction_indices = [1]))
#train step
train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)

#initialize the NN
init = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init)

for i in range(1000):
	sess.run(train_step, feed_dict = {x:x_data, y:y_data})
	if i % 50 == 0:
		print(sess.run(loss, feed_dict = {x:x_data, y:y_data}))
		
print(sess.run(prediction, feed_dict = {x:x_data}))
