import tensorflow as tf
from tensorflow.python import debug as tf_debug
import numpy as np

#define NN
def add_layer(inputs, in_size, out_size, activation_func = None ):
	
	Weights = tf.Variable(tf.random_normal([in_size, out_size]))
	biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)
	Wx_plus_b = tf.matmul(inputs, Weights) + biases

	if activation_func is None:
		outputs = Wx_plus_b
	else:
		outputs = activation_func(Wx_plus_b)
	
	return outputs

#input data generated by scoreGenerator.py
fin = open('input.txt', 'r')
datas = fin.readlines()
x_data = []
y_data = []
for line in datas:
	line.strip('\n')
	temp =  line.split(" ")
	x_data.append([int(temp[0]), int(temp[1])])
	y_data.append([int(temp[2])])
del temp
x_data = np.array(x_data)
y_data = np.array(y_data)

x = tf.placeholder(tf.float32, [None, 2])
y = tf.placeholder(tf.float32, [None, 1])


#There are two layer
layer1 = add_layer(x, 2, 10, activation_func = tf.nn.relu6)
prediction = add_layer(layer1, 10, 1, activation_func = None)

#loss for train
loss = tf.losses.mean_squared_error(labels = y, predictions = prediction)
#train step
train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)

#initialize the NN
init = tf.initialize_all_variables()
sess = tf.Session()
#this is debug session
#sess = tf_debug.LocalCLIDebugWrapperSession(sess)
sess.run(init)

for i in range(20000):
	sess.run(train_step, feed_dict = {x:x_data, y:y_data})
	if i % 50 == 0:
		sess.run(loss, feed_dict = {x:x_data, y:y_data})

#print result
pred = sess.run(prediction, feed_dict = {x:x_data})		
print("input      prediction  real output")
for i in range(len(pred)):
	print("[%3d,%3d]  [%5.2f]     [%3d]"
					 % (x_data[i][0],x_data[i][1],pred[i],y_data[i]))

